version: "3.8"

services:
  # MongoDB Database
  mongodb:
    image: mongo:7.0
    container_name: youtube-mongodb
    restart: always
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_DATABASE: youtube_trending
      MONGO_URI: mongodb://mongodb:27017/
    volumes:
      - mongodb_data:/data/db
      - ./mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - youtube-network

  # MongoDB Express (Web UI)
  mongo-express:
    image: mongo-express:1.0.0
    container_name: youtube-mongo-express
    restart: always
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_URL: mongodb://mongodb:27017/
      ME_CONFIG_BASICAUTH: false
    depends_on:
      - mongodb
    networks:
      - youtube-network

  # HDFS NameNode
  hdfs-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: youtube-hdfs-namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=youtube-hadoop
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
      - HDFS_CONF_dfs_permissions_enabled=false
    ports:
      - "9870:9870"  # NameNode Web UI
      - "9000:9000"  # NameNode RPC
    volumes:
      - hdfs_namenode:/hadoop/dfs/name
      - ../data:/input-data  # Mount local data for initial upload
    networks:
      - youtube-network

  # HDFS DataNode
  hdfs-datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: youtube-hdfs-datanode
    hostname: datanode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
      - HDFS_CONF_dfs_permissions_enabled=false
    volumes:
      - hdfs_datanode:/hadoop/dfs/data
    depends_on:
      - hdfs-namenode
    networks:
      - youtube-network

  # HDFS Data Uploader (One-time initialization)
  hdfs-init:
    image: bde2020/hadoop-base:2.0.0-hadoop3.2.1-java8
    container_name: youtube-hdfs-init
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    volumes:
      - ../data:/input-data
      - ./hdfs-init.sh:/hdfs-init.sh
    depends_on:
      - hdfs-namenode
      - hdfs-datanode
    command: ["bash", "/hdfs-init.sh"]
    networks:
      - youtube-network

  # Spark Master (Updated with HDFS integration)
  spark-master:
    image: bitnami/spark:3.5
    container_name: youtube-spark-master
    environment:
      - SPARK_MODE=master
      - MONGO_URI=mongodb://mongodb:27017/
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HDFS_NAMENODE_URL=hdfs://namenode:9000
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ../spark:/opt/bitnami/spark/jobs
      - ../data:/opt/bitnami/spark/data
    depends_on:
      - hdfs-namenode
      - hdfs-datanode
    networks:
      - youtube-network

  # Spark Worker (Updated with HDFS integration)
  spark-worker:
    image: bitnami/spark:3.5
    container_name: youtube-spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - MONGO_URI=mongodb://mongodb:27017/
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - HDFS_NAMENODE_URL=hdfs://namenode:9000
    depends_on:
      - spark-master
      - hdfs-namenode
      - hdfs-datanode
    volumes:
      - ../spark:/opt/bitnami/spark/jobs
      - ../data:/opt/bitnami/spark/data
    networks:
      - youtube-network

volumes:
  mongodb_data:
  hdfs_namenode:
  hdfs_datanode:

networks:
  youtube-network:
    driver: bridge
